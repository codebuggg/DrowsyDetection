{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NNZnPTj3wsll"
   },
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3H7H8u1pwslo",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import imutils\n",
    "from imutils import face_utils\n",
    "from scipy.spatial import distance\n",
    "import dlib\n",
    "import IPython\n",
    "from IPython.display import Audio\n",
    "import argparse\n",
    "#import pygame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JN1F_tPVwslv"
   },
   "source": [
    "### Define Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LMSZOdYUwsly"
   },
   "outputs": [],
   "source": [
    "def showImg(img, title = ''):\n",
    "    plt.figure(figsize = (20,15));\n",
    "    plt.title(title)\n",
    "    plt.imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RBG))\n",
    "    \n",
    "def GrayImg(img, title = ''):\n",
    "    plt.figure(figsize = (20,15));\n",
    "    plt.title(title)\n",
    "    plt.imshow(cv2.cvtColor(img,cv2.COLOR_BGR2GRAY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r6i2QfGXwsl3"
   },
   "source": [
    "### HAAR Cascades for face detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AOgOAl91wsl4"
   },
   "outputs": [],
   "source": [
    "face_classifier = cv2.CascadeClassifier('Haarcascades/haarcascade_frontalface_default.xml')\n",
    "eye_classifier = cv2.CascadeClassifier('Haarcascades/haarcascade_eye.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 416
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1699,
     "status": "ok",
     "timestamp": 1568016798303,
     "user": {
      "displayName": "God Girl",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAkQbOyssRBd1afWo0j6aJkgwH8zZgqMa5oDQ6Ekg=s64",
      "userId": "09229993686372536494"
     },
     "user_tz": -120
    },
    "id": "ZsT0-iywWyZh",
    "outputId": "c28bcc5d-0164-4513-969d-8deb5fe94472"
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('face.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = face_classifier.detectMultiScale(img, 1.3, 5)\n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "    roi_gray = gray[y:y+h, x:x+w]\n",
    "    roi_color = img[y:y+h, x:x+w]\n",
    "    eyes = eye_classifier.detectMultiScale(roi_gray)\n",
    "    for (ex,ey,ew,eh) in eyes:\n",
    "        cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "        \n",
    "\n",
    "cv2.imshow('image', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect Parts of the Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# USAGE\n",
    "# python detect_face_parts.py --shape-predictor shape_predictor_68_face_landmarks.dat --image images/example_01.jpg \n",
    "\n",
    "# import the necessary packages\n",
    "from imutils import face_utils\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import dlib\n",
    "import cv2\n",
    "\n",
    "# initialize dlib's face detector\n",
    "# the facial landmark predictor\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "# load the input image, resize it, and convert it to grayscale\n",
    "image = cv2.imread('face.jpg')\n",
    "image = imutils.resize(image, width=500)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# detect faces in the grayscale image\n",
    "rects = detector(gray, 1)\n",
    "\n",
    " #rects = detector(gray, 0)\n",
    "    \n",
    "    # For each detected face, find the landmark.\n",
    "for (i, rect) in enumerate(rects):\n",
    "        # Make the prediction and transfom it to numpy array\n",
    "    shape = predictor(gray, rect)\n",
    "    shape = face_utils.shape_to_np(shape)\n",
    "    \n",
    "        # Draw on our image, all the finded cordinate points (x,y) \n",
    "    for (x, y) in shape:\n",
    "         cv2.circle(image, (x, y), 2, (0, 255, 0), -1)\n",
    "    \n",
    "    # Show the image\n",
    "cv2.imshow(\"Output\", image)\n",
    "\t# visualize all facial landmarks with a transparent overlay\n",
    "# \t\n",
    "\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply EAR to Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup text\n",
    "img = cv2.imread('face.jpg')\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "text = \"SLEEPY!!!\"\n",
    "text2 = \"You're Wide Awake\"\n",
    "# get boundary of this text\n",
    "textsize = cv2.getTextSize(text, font, 1, 2)[0]\n",
    "textsize2 = cv2.getTextSize(text2, font, 1, 2)[0]\n",
    "\n",
    "# get coords based on boundary\n",
    "textX = int((img.shape[1] - textsize[0]) / 2)\n",
    "textY = int((img.shape[0] + textsize[1]) / 2)\n",
    "\n",
    "text2X = int((img.shape[1] - textsize2[0]) / 2)\n",
    "text2Y = int((img.shape[0] + textsize2[1]) / 2)\n",
    "\n",
    "\n",
    "# add text centered on image\n",
    "# cv2.putText(img, text, (textX, textY ), font, 1, (255, 255, 255), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('sleep.jpg')\n",
    "sound = 'audio/alert.wav'\n",
    "alarm_on = False\n",
    "thresh = 0.25\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor_path = \"shape_predictor_68_face_landmarks.dat\"\n",
    "predictor = dlib.shape_predictor(predictor_path)\n",
    "\n",
    "def eye_aspect_ratio(eye):\n",
    "  A = distance.euclidean(eye[1], eye[5])\n",
    "  B = distance.euclidean(eye[2], eye[4])\n",
    "  C = distance.euclidean(eye[0], eye[3])\n",
    "  ear = (A + B)/ (2.0 * C)\n",
    "  return ear\n",
    "\n",
    "(lStart, lEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"left_eye\"]\n",
    "(rStart, rEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"right_eye\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = detector(gray, 0)\n",
    "face_rectangle = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "for (x,y,w,h) in face_rectangle:\n",
    "  cv2.rectangle(img, (x,y), (x+w,y+h), (255,0,0), 2)\n",
    "  \n",
    "for face in faces:\n",
    "  \n",
    "  shape = predictor(gray,face)\n",
    "  shape = face_utils.shape_to_np(shape)\n",
    "  \n",
    "  leftEye = shape[lStart:lEnd]\n",
    "  rightEye = shape[rStart:rEnd]\n",
    "\n",
    "  #Calculate aspect ratio of both eyes\n",
    "  leftEyeAspectRatio = eye_aspect_ratio(leftEye)\n",
    "  rightEyeAspectRatio = eye_aspect_ratio(rightEye)\n",
    "  \n",
    "  eyeAspectRatio = (leftEyeAspectRatio + rightEyeAspectRatio) / 2\n",
    "  \n",
    "  leftEyeHull = cv2.convexHull(leftEye)\n",
    "  rightEyeHull = cv2.convexHull(rightEye)\n",
    "  cv2.drawContours(img, [leftEyeHull], -1, (0, 255, 0), 1)\n",
    "  cv2.drawContours(img, [rightEyeHull], -1, (0, 255, 0), 1)\n",
    "  \n",
    "  if(eyeAspectRatio < thresh):\n",
    "        cv2.putText(img, text, (textX, textY ), font, 2, (0, 0, 255), 2)\n",
    "    #cv2.putText(img,\"SLEEPY!!!\",(120,0), cv2.FONT_HERSHEY_COMPLEX, 1 ,(0,0,255), 2)\n",
    "    \n",
    "  else:\n",
    "    #cv2.putText(img, text2, (text2X, text2Y ), font, 1, (0, 0, 255), 2)\n",
    "    cv2.putText(img,\"You're wide awake\",(120,25), cv2.FONT_HERSHEY_COMPLEX, 1 ,(0,0,255), 2)  \n",
    "#     print(\"You're wide awake\")\n",
    "    \n",
    "cv2.imshow('image', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hello(): \n",
    "    IPython.display.Audio(sound, autoplay=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6bU0L-js9Ejw"
   },
   "source": [
    "### HAAR Cascade for Face Detection (Video) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "flag = 0\n",
    "while True:\n",
    "    ret,frame = cap.read()\n",
    "    frame = imutils.resize(frame, width = 450)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord(\"q\"):\n",
    "        cv2.destroyAllWindows()\n",
    "        cap.release()\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(sound, autoplay=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "flag = 0\n",
    "frame_check = 20\n",
    "thresh = 0.25\n",
    "sound = 'audio/alert.wav'\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor_path = \"shape_predictor_68_face_landmarks.dat\"\n",
    "predictor = dlib.shape_predictor(predictor_path)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "flag = 0\n",
    "while True:\n",
    "    ret,frame = cap.read()\n",
    "    frame = imutils.resize(frame, width = 450)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = detector(gray, 0)\n",
    "    face_rectangle = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "    for (x,y,w,h) in face_rectangle:\n",
    "        cv2.rectangle(img, (x,y), (x+w,y+h), (255,0,0), 2)\n",
    "    for face in faces:\n",
    "  \n",
    "      shape = predictor(gray,face)\n",
    "      shape = face_utils.shape_to_np(shape)\n",
    "  \n",
    "      leftEye = shape[lStart:lEnd]\n",
    "      rightEye = shape[rStart:rEnd]\n",
    "        \n",
    "    \n",
    "    \n",
    "    #Calculate aspect ratio of both eyes\n",
    "      leftEyeAspectRatio = eye_aspect_ratio(leftEye)\n",
    "      rightEyeAspectRatio = eye_aspect_ratio(rightEye)\n",
    "\n",
    "      eyeAspectRatio = (leftEyeAspectRatio + rightEyeAspectRatio) / 2\n",
    "\n",
    "      leftEyeHull = cv2.convexHull(leftEye)\n",
    "      rightEyeHull = cv2.convexHull(rightEye)\n",
    "      cv2.drawContours(img, [leftEyeHull], -1, (0, 255, 0), 1)\n",
    "      cv2.drawContours(img, [rightEyeHull], -1, (0, 255, 0), 1)\n",
    "\n",
    "      if(eyeAspectRatio < thresh):\n",
    "        flag += 1\n",
    "        #print (flag)\n",
    "        if flag >= frame_check:\n",
    "            \n",
    "            Audio(sound, autoplay=True)\n",
    "            cv2.putText(frame, \"****************ALERT!****************\", (10, 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "            cv2.putText(frame, \"****************ALERT!****************\", (10,325),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "            #cv2.putText(img, text, (textX, textY ), font, 2, (0, 0, 255), 2)\n",
    "        #cv2.putText(img,\"SLEEPY!!!\",(120,0), cv2.FONT_HERSHEY_COMPLEX, 1 ,(0,0,255), 2)\n",
    "\n",
    "      else:\n",
    "        Audio(sound, autoplay=False)\n",
    "        flag = 0\n",
    "        #cv2.putText(img, text2, (text2X, text2Y ), font, 1, (0, 0, 255), 2)\n",
    "        #cv2.putText(img,\"You're wide awake\",(120,25), cv2.FONT_HERSHEY_COMPLEX, 1 ,(0,0,255), 2)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord(\"q\"):\n",
    "        cv2.destroyAllWindows()\n",
    "        cap.release()\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\t\tif ear < thresh:\n",
    "\t\t\tflag += 1\n",
    "\t\t\t#print (flag)\n",
    "\t\t\tif flag >= frame_check:\n",
    "\t\t\t\tcv2.putText(frame, \"****************ALERT!****************\", (10, 30),\n",
    "\t\t\t\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "\t\t\t\tcv2.putText(frame, \"****************ALERT!****************\", (10,325),\n",
    "\t\t\t\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "\t\telse:\n",
    "\t\t\tflag = 0\n",
    "\tcv2.imshow(\"Frame\", frame)\n",
    "\tkey = cv2.waitKey(1) & 0xFF\n",
    "\tif key == ord(\"q\"):\n",
    "\t\tcv2.destroyAllWindows()\n",
    "\t\tcap.release()\n",
    "\t\tbreak\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = detector(gray, 0)\n",
    "face_rectangle = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "for (x,y,w,h) in face_rectangle:\n",
    "  cv2.rectangle(img, (x,y), (x+w,y+h), (255,0,0), 2)\n",
    "  \n",
    "for face in faces:\n",
    "  \n",
    "  shape = predictor(gray,face)\n",
    "  shape = face_utils.shape_to_np(shape)\n",
    "  \n",
    "  leftEye = shape[lStart:lEnd]\n",
    "  rightEye = shape[rStart:rEnd]\n",
    "\n",
    "  #Calculate aspect ratio of both eyes\n",
    "  leftEyeAspectRatio = eye_aspect_ratio(leftEye)\n",
    "  rightEyeAspectRatio = eye_aspect_ratio(rightEye)\n",
    "  \n",
    "  eyeAspectRatio = (leftEyeAspectRatio + rightEyeAspectRatio) / 2\n",
    "  \n",
    "  leftEyeHull = cv2.convexHull(leftEye)\n",
    "  rightEyeHull = cv2.convexHull(rightEye)\n",
    "  cv2.drawContours(img, [leftEyeHull], -1, (0, 255, 0), 1)\n",
    "  cv2.drawContours(img, [rightEyeHull], -1, (0, 255, 0), 1)\n",
    "  \n",
    "  if(eyeAspectRatio < thresh):\n",
    "        cv2.putText(img, text, (textX, textY ), font, 2, (0, 0, 255), 2)\n",
    "    #cv2.putText(img,\"SLEEPY!!!\",(120,0), cv2.FONT_HERSHEY_COMPLEX, 1 ,(0,0,255), 2)\n",
    "    \n",
    "  else:\n",
    "    #cv2.putText(img, text2, (text2X, text2Y ), font, 1, (0, 0, 255), 2)\n",
    "    cv2.putText(img,\"You're wide awake\",(120,25), cv2.FONT_HERSHEY_COMPLEX, 1 ,(0,0,255), 2)  \n",
    "#     print(\"You're wide awake\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = face_classifier.detectMultiScale(img, 1.3, 5)\n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "    roi_gray = gray[y:y+h, x:x+w]\n",
    "    roi_color = img[y:y+h, x:x+w]\n",
    "    eyes = eye_classifier.detectMultiScale(roi_gray)\n",
    "    for (ex,ey,ew,eh) in eyes:\n",
    "        cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M_OnSms2PVUN"
   },
   "source": [
    "### Capture Video from WebCam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 655,
     "status": "error",
     "timestamp": 1568017290078,
     "user": {
      "displayName": "God Girl",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAkQbOyssRBd1afWo0j6aJkgwH8zZgqMa5oDQ6Ekg=s64",
      "userId": "09229993686372536494"
     },
     "user_tz": -120
    },
    "id": "wCiJ8SaH89BX",
    "outputId": "d85409db-cb29-4a31-b634-9943b0d1e2e6"
   },
   "outputs": [],
   "source": [
    "video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "#read frames from webcam\n",
    "while True:\n",
    "  ret, frame = video_capture.read()\n",
    "  frame = cv2.flip(frame,1)\n",
    "  #gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "  \n",
    "  faces = face_classifier.detectMultiScale(frame, 1.3, 5)\n",
    "  \n",
    "  for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(frame, (x,y), (x+w,y+h), (255,0,0), 2)\n",
    "    roi_gray = gray[y:y+h, x:x+w]\n",
    "    roi_color = frame[y:y+h, x:x+w]\n",
    "    \n",
    "    eyes = eye_classifier.detectMultiScale(roi_gray)\n",
    "    \n",
    "    for (ex,ey,ew,eh) in eyes:\n",
    "      cv2.rectangle(roi_color,(ex,ey), (ex+ew, ey+eh), (0,255,0), 2)\n",
    "      \n",
    "  #cv2_imshow( frame)\n",
    "  cv2.imshow('frame',frame)\n",
    "  if(cv2.waitKey(1) & 0xFF == ord('q')):\n",
    "    break\n",
    "    \n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5KHzG_LEH4j2"
   },
   "source": [
    "### Eye Aspect Ratio Algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2dydEi8YIATp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pwcIOEp_KmFA"
   },
   "outputs": [],
   "source": [
    "thresh = 0.25\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor_path = \"shape_predictor_68_face_landmarks.dat\"\n",
    "predictor = dlib.shape_predictor(predictor_path)\n",
    "\n",
    "def eye_aspect_ratio(eye):\n",
    "  A = distance.euclidean(eye[1], eye[5])\n",
    "  B = distance.euclidean(eye[2], eye[4])\n",
    "  C = distance.euclidean(eye[0], eye[3])\n",
    "  ear = (A + B)/ (2.0 * C)\n",
    "  return ear\n",
    "\n",
    "(lStart, lEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"left_eye\"]\n",
    "(rStart, rEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"right_eye\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = detector(gray, 0)\n",
    "face_rectangle = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "for (x,y,w,h) in face_rectangle:\n",
    "  cv2.rectangle(img, (x,y), (x+w,y+h), (255,0,0), 2)\n",
    "  \n",
    "for face in faces:\n",
    "  \n",
    "  shape = predictor(gray,face)\n",
    "  shape = face_utils.shape_to_np(shape)\n",
    "  \n",
    "  leftEye = shape[lStart:lEnd]\n",
    "  rightEye = shape[rStart:rEnd]\n",
    "\n",
    "  #Calculate aspect ratio of both eyes\n",
    "  leftEyeAspectRatio = eye_aspect_ratio(leftEye)\n",
    "  rightEyeAspectRatio = eye_aspect_ratio(rightEye)\n",
    "  \n",
    "  eyeAspectRatio = (leftEyeAspectRatio + rightEyeAspectRatio) / 2\n",
    "  \n",
    "  leftEyeHull = cv2.convexHull(leftEye)\n",
    "  rightEyeHull = cv2.convexHull(rightEye)\n",
    "  cv2.drawContours(img, [leftEyeHull], -1, (0, 255, 0), 1)\n",
    "  cv2.drawContours(img, [rightEyeHull], -1, (0, 255, 0), 1)\n",
    "  \n",
    "  if(eyeAspectRatio < thresh):\n",
    "    print('Sleepy Eyes')\n",
    "    \n",
    "  else:\n",
    "    print(\"You're wide awake\")\n",
    "    \n",
    "cv2_imshow(img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CDKsUSGoMuiS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 651
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1471,
     "status": "ok",
     "timestamp": 1567984794957,
     "user": {
      "displayName": "God Girl",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAkQbOyssRBd1afWo0j6aJkgwH8zZgqMa5oDQ6Ekg=s64",
      "userId": "09229993686372536494"
     },
     "user_tz": -120
    },
    "id": "PXgKQcJjLI0P",
    "outputId": "707644f4-f14c-4382-e13f-c5eaff72be3e"
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('sleep.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = detector(gray, 0)\n",
    "face_rectangle = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "for (x,y,w,h) in face_rectangle:\n",
    "  cv2.rectangle(img, (x,y), (x+w,y+h), (255,0,0), 2)\n",
    "  \n",
    "for face in faces:\n",
    "  \n",
    "  shape = predictor(gray,face)\n",
    "  shape = face_utils.shape_to_np(shape)\n",
    "  \n",
    "  leftEye = shape[lStart:lEnd]\n",
    "  rightEye = shape[rStart:rEnd]\n",
    "\n",
    "  #Calculate aspect ratio of both eyes\n",
    "  leftEyeAspectRatio = eye_aspect_ratio(leftEye)\n",
    "  rightEyeAspectRatio = eye_aspect_ratio(rightEye)\n",
    "  \n",
    "  eyeAspectRatio = (leftEyeAspectRatio + rightEyeAspectRatio) / 2\n",
    "  \n",
    "  leftEyeHull = cv2.convexHull(leftEye)\n",
    "  rightEyeHull = cv2.convexHull(rightEye)\n",
    "  cv2.drawContours(img, [leftEyeHull], -1, (0, 255, 0), 1)\n",
    "  cv2.drawContours(img, [rightEyeHull], -1, (0, 255, 0), 1)\n",
    "  \n",
    "  if(eyeAspectRatio < thresh):\n",
    "    print('Sleepy Eyes')\n",
    "    \n",
    "  else:\n",
    "    print(\"You're wide awake\")\n",
    "    \n",
    "cv2_imshow(img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UfTlM-tsoVzD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BsFvSIE4wsl9"
   },
   "outputs": [],
   "source": [
    "# detect_face = cv2.CascadeClassifier('Haarcascades/haarcascade_frontalface_default.xml')\n",
    "# eye_classifier = cv2.CascadeClassifier('Haarcascades/haarcascade_eye.xml')\n",
    "\n",
    "# def face_detector(img, size = 0.5):\n",
    "#     #convert image to gray\n",
    "#     gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "#     faces = detect_face.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "#     # When no faces detected:\n",
    "#     if faces is ():\n",
    "#         return img\n",
    "    \n",
    "#     #if a face is found, draw a rectangle over the face.\n",
    "#     for (x,y,w,h) in faces:\n",
    "#         cv2.rectangle(img, (x,y), (x+w,y+h), (127,0,255), 2)\n",
    "    \n",
    "\n",
    "# cap = cv2.VideoCapture(0)\n",
    "\n",
    "# while True:\n",
    "#     frame = cv2.imread('img',0)\n",
    "#     ret,frame = cap.read()\n",
    "#     GrayImg('Face Detection', face_detector(frame))\n",
    "#     if cv2.waitKey(1) == 12:\n",
    "#         break\n",
    "        \n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SiRx7pevwsmJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lTbTVVeHwsmO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D-QK8M36wsmT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yyxkd_CHwsmY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nJsb4wUbwsme"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Sleepy Eyes.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
